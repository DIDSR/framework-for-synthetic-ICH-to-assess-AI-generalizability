{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CAD model on real dataset<sup>1,2</sup>\n",
    "### Dataset cannot be automatically downloaded, please sign data use agreement here: https://physionet.org/content/ct-ich/1.3.1/\n",
    "\n",
    "1. Hssayeni, M. (2020). Computed Tomography Images for Intracranial Hemorrhage Detection and Segmentation (version 1.3.1). PhysioNet. https://doi.org/10.13026/4nae-zg36.\n",
    "2. Goldberger, A., et al (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215â€“e220."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayse.weaver/anaconda3/envs/insilicoich/lib/python3.11/site-packages/albumentations/check_version.py:107: UserWarning: Error fetching version info <urlopen error [Errno 101] Network is unreachable>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "# load and create dataframes\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from image_utils import *\n",
    "from model_utils import *\n",
    "\n",
    "path = Path('../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/') # TODO: change directory\n",
    "scan_path = Path.joinpath(path, 'ct_scans')\n",
    "\n",
    "# load a modified version of Patient_demographics with cleaner headers\n",
    "df = pd.read_csv('../datasets/MODIFIED_Patient_demographics.csv')\n",
    "df = df.drop(df.columns[4:], axis=1) # remove lesion types\n",
    "df.loc[df['Any_ICH'] != 0, 'Any_ICH'] = 1 # change # of ICH subtypes to binary 1/0\n",
    "df['Model_Output'] = np.nan # add model output column\n",
    "\n",
    "# there are six patients in Patient_demographics.csv with no images in the dataset; remove them\n",
    "no_ct = [59, 60, 61, 61, 62, 63, 64, 65]\n",
    "for case in no_ct:\n",
    "    df.drop(df[df['Patient Number'] == case].index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Run CAD on real data\n",
    "label_cols = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "options = {\n",
    "    'size': (480, 480),\n",
    "    'save_jpg': False,\n",
    "    'save_csv': True,\n",
    "    'verbose': False,\n",
    "    'native_resolution': True\n",
    "}\n",
    "\n",
    "if os.path.isfile('../datasets/real_dataset_predictions.csv'):\n",
    "    df = pd.read_csv('../datasets/real_dataset_predictions.csv')\n",
    "else:\n",
    "    with tqdm(total=len(df)) as pbar:\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            nifti_path = Path.joinpath(scan_path, str(row['Patient Number']).zfill(3) + '.nii') #row['Patient Number']\n",
    "\n",
    "            try:\n",
    "                img, files = prepare_images(nifti_path, options, str(row['Patient Number']).zfill(3), 'saved_images/')\n",
    "\n",
    "                output = classify_images(img, options)\n",
    "                \n",
    "                df.loc[index, 'Model_Output'] = np.max(output[:, -1]) # right now just want max value in the \"any\" category\n",
    "            except:\n",
    "                print('error')\n",
    "\n",
    "    if options['save_csv']:\n",
    "        df.to_csv('../datasets/real_dataset_predictions.csv')\n",
    "\n",
    "results_real = df[[\"Any_ICH\", \"Model_Output\"]].to_numpy()\n",
    "\n",
    "# Get ROC\n",
    "fpr_real, tpr_real, thresholds_real = metrics.roc_curve(df[\"Any_ICH\"].to_numpy(), df[\"Model_Output\"].to_numpy(), pos_label=1)\n",
    "roc_df_real = pd.DataFrame(zip(fpr_real, tpr_real, thresholds_real),columns = [\"FPR\",\"TPR\",\"Threshold\"])\n",
    "\n",
    "roc_auc = metrics.auc(fpr_real, tpr_real)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic for Whole-Volume Level Detection')\n",
    "plt.plot(fpr_real, tpr_real, 'bo-', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CAD model on synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'size': (480, 480),\n",
    "    'save_jpg': False,\n",
    "    'save_csv': True,\n",
    "    'verbose': False,\n",
    "    'native_resolution': False # synthetic data is 1 mm, \"True\" will reformat to 5 mm\n",
    "}\n",
    "\n",
    "dataset_path = Path('../datasets')\n",
    "dataset_names = ['mA_280_run1', 'mA_280_run2', 'mA_280_run3']\n",
    "\n",
    "save_dir = '/home/jayse.weaver/temp_images/' # optional save directory if save_jpg = True\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    print('Processing dataset: ' + str(dataset))\n",
    "    path = dataset_path / dataset\n",
    "    metadata = pd.concat([pd.read_csv(o) for o in path.rglob('metadata*.csv')], ignore_index=True)\n",
    "\n",
    "    if options['save_csv']: metadata.to_csv(path / (str(dataset) + '_metadata.csv'))\n",
    "\n",
    "    metadata_short = metadata.drop(metadata.columns[12:], axis=1)\n",
    "    metadata_dropna = metadata_short.dropna()\n",
    "\n",
    "    cases = sorted(os.listdir(path))\n",
    "    cases = [case for case in cases if case.startswith('case')]\n",
    "\n",
    "    labels_syn = []\n",
    "    pred_syn = []\n",
    "    type_syn = []\n",
    "    volume_syn = []\n",
    "    intensity_syn = []\n",
    "\n",
    "    if options['native_resolution']:\n",
    "        print('Processing in native resolution')\n",
    "    else:\n",
    "        print('Processing in 5 mm resolution')\n",
    "\n",
    "    max_count = len(cases)\n",
    "    description = 'Processing ' + str(len(cases)) + ' cases'\n",
    "\n",
    "    with tqdm(total=max_count) as pbar:\n",
    "        for index, case in enumerate(cases):\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "            id = str(case)\n",
    "            if os.path.isdir(Path.joinpath(path, case, 'lesion_masks/')): # check if case has mask and therefore hemorrhage\n",
    "                labels_syn.append(1)\n",
    "\n",
    "                # if case has hemorrhage, extract metadata from dataframe\n",
    "                temp_df = metadata_dropna.loc[metadata_dropna['name'] == case]\n",
    "                type_syn.append(temp_df['lesion type'].unique())\n",
    "                volume_syn.append(temp_df['lesion volume [mL]'].sum())\n",
    "                intensity_syn.append(temp_df['intensity'].unique())\n",
    "            else: # case has no mask, therefore no hemorrhage\n",
    "                labels_syn.append(0)\n",
    "                type_syn.append('None')\n",
    "                volume_syn.append('NaN')\n",
    "                intensity_syn.append('NaN')\n",
    "\n",
    "            dcm_path = Path.joinpath(path, case, 'dicoms/')\n",
    "\n",
    "            img, files = prepare_images(dcm_path, options, id, save_dir)\n",
    "            output = classify_images(img, options)\n",
    "            pred_syn.append(np.max(output[:, -1]))\n",
    "\n",
    "            if options['verbose']: print(np.max(output[:, -1]))\n",
    "\n",
    "    fpr_syn, tpr_syn, thresholds_syn = metrics.roc_curve(labels_syn, pred_syn, pos_label=1)\n",
    "    roc_df_syn = pd.DataFrame(zip(fpr_syn, tpr_syn, thresholds_syn),columns = [\"FPR\",\"TPR\",\"Threshold\"])\n",
    "\n",
    "    if options['save_csv']: metadata.to_csv(path / (str(dataset) + '_ROC.csv'))\n",
    "\n",
    "    roc_auc_syn = metrics.auc(fpr_syn, tpr_syn)\n",
    "\n",
    "    all_cases = cases.copy()\n",
    "\n",
    "    dfsyn = pd.DataFrame()\n",
    "    dfsyn['case'] = all_cases\n",
    "    dfsyn['truth'] = labels_syn\n",
    "    dfsyn['pred'] = pred_syn\n",
    "    dfsyn['type'] = type_syn\n",
    "    dfsyn['volume'] = volume_syn\n",
    "    dfsyn['intensity'] = intensity_syn\n",
    "\n",
    "    if options['save_csv']: metadata.to_csv(path / (str(dataset) + '_results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insilicoich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
