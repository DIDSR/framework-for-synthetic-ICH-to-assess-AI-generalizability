{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: Compile hemorrhage characteristics from Hssayeni dataset\n",
    "### Creates and saves volume (mL) and attenuation (HU) distributions from Hssayeeni dataset.\n",
    "### Modified from `get_BHSD_distributions.ipynb`\n",
    "\n",
    "Hssayeni dataset cannot be downloaded via URL, please sign data use agreement:\n",
    "https://physionet.org/content/ct-ich/1.3.1/\n",
    "\n",
    "Download our further segmented hemorrhage masks: [TODO: LINK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save Pandas dataframe with BHSD hemorrhage characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "049.nii\n",
      "number of EDH clusters: 2\n",
      "cluster idx: 1, count: 3799\n",
      "cluster idx: 2, count: 2077\n",
      "number of IPH clusters: 2\n",
      "cluster idx: 1, count: 109\n",
      "cluster idx: 2, count: 184\n",
      "    Dataset  Data_ID Type  Volume_[mL]    Mean_HU  Median_HU        dx  \\\n",
      "0  Hssayeni  049.nii  EDH     3.225999  56.981048       60.0  0.412109   \n",
      "1  Hssayeni  049.nii  EDH     1.763727  75.128551       73.0  0.412109   \n",
      "2  Hssayeni  049.nii  IPH     0.092560  50.825688       49.0  0.412109   \n",
      "3  Hssayeni  049.nii  IPH     0.156247  36.826087       35.0  0.412109   \n",
      "\n",
      "         dy   dz  num_slices  z_dist  \n",
      "0  0.412109  5.0           4    20.0  \n",
      "1  0.412109  5.0           4    20.0  \n",
      "2  0.412109  5.0           1     5.0  \n",
      "3  0.412109  5.0           1     5.0  \n",
      "050.nii\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/masks_subtype/050.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/insilicoich-pub1/lib/python3.11/site-packages/nibabel/loadsave.py:101\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/masks_subtype/050.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m [dx, dy, dz] \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mheader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixdim\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     42\u001b[0m image \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m---> 44\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruth_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(labels)): \u001b[38;5;66;03m# skip background\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     hemorrhage_volume \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39margwhere(mask \u001b[38;5;241m==\u001b[39m label_idx)))\u001b[38;5;241m*\u001b[39m((dx\u001b[38;5;241m*\u001b[39mdy\u001b[38;5;241m*\u001b[39mdz)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/insilicoich-pub1/lib/python3.11/site-packages/nibabel/loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/masks_subtype/050.nii'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import *\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import skimage as sk\n",
    "\n",
    "regenerate_spreadsheet = True\n",
    "save_distributions = True\n",
    "verbose = True # set to False to disable pesky things like printing file IDs and cluster numbers used for debugging\n",
    "\n",
    "Hssayeni_path = Path('../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1') # TODO: move to public location if necessary\n",
    "\n",
    "if not regenerate_spreadsheet:\n",
    "    try:\n",
    "        df = pd.read_csv('../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/Hssayeni_hemorrhage_characteristics.csv')\n",
    "        print('Found Hssayeni spreadsheet')\n",
    "    except:\n",
    "        print('CSV not found, regenerating spreadsheet...')\n",
    "        regenerate_spreadsheet = True\n",
    "\n",
    "if regenerate_spreadsheet:\n",
    "    # initialize empty dataframe\n",
    "    df = pd.DataFrame(columns=['Dataset', 'Data_ID', 'Type', 'Volume_[mL]', 'Mean_HU', 'Median_HU', 'dx', 'dy', 'dz', 'num_slices', 'z_dist'])\n",
    "\n",
    "    cluster_threshold = 15 # clusters an area less than this number (in voxels) are excluded, necessary because manual and automatic segmentation leave some spurious clusters of voxels\n",
    "\n",
    "    labels = [\"bkg\", \"EDH\", \"IPH\", \"IVH\", \"SAH\", \"SDH\"] # 0, 1, 2, 3, 4, 5; labels used by BHSD dataset creators\n",
    "\n",
    "    img_dir = Hssayeni_path / \"ct_scans\"\n",
    "    truth_dir = Hssayeni_path / \"masks_subtype\"\n",
    "\n",
    "    row_idx = 0\n",
    "\n",
    "    label_names = sorted(os.listdir(img_dir))\n",
    "\n",
    "    for idx, file in enumerate(label_names):\n",
    "        if verbose: print(str(file))\n",
    "        img = nib.load(img_dir / file)\n",
    "        [dx, dy, dz] = img.header['pixdim'][1:4]\n",
    "        image = img.get_fdata()\n",
    "\n",
    "        mask = nib.load(truth_dir / file).get_fdata()\n",
    "\n",
    "        for label_idx in range(1, len(labels)): # skip background\n",
    "\n",
    "            hemorrhage_volume = (len(np.argwhere(mask == label_idx)))*((dx*dy*dz)/1000)\n",
    "\n",
    "            if hemorrhage_volume != 0:\n",
    "                hemorrhage_mask = np.where(mask == label_idx, 1, 0) # create new hemorrhage mask for corresponding lesion type\n",
    "\n",
    "                label_mask, num = sk.measure.label(hemorrhage_mask, return_num=True, connectivity=1)\n",
    "                if verbose: print('number of ' + str(labels[label_idx]) + ' clusters: ' + str(num))\n",
    "\n",
    "                for cluster_idx in range(1,num+1):\n",
    "                    cluster = np.where(label_mask == cluster_idx, 1, 0)\n",
    "                    if verbose: print('cluster idx: '+str(cluster_idx)+', count: '+str(np.count_nonzero(cluster)))\n",
    "                    if np.count_nonzero(cluster) > cluster_threshold:\n",
    "                        num_slices = 0\n",
    "                        for slice_idx in range(cluster.shape[2]):\n",
    "                            slice = cluster[:, :, slice_idx]\n",
    "                            if np.any(slice): # check if hemorrhage\n",
    "                                num_slices += 1\n",
    "\n",
    "                        hemorrhage_volume = (len(np.argwhere(cluster == 1)))*((dx*dy*dz)/1000)\n",
    "\n",
    "                        z_dist = num_slices * dz\n",
    "\n",
    "                        # calculate mean and median HU\n",
    "                        lesion_only = np.multiply(image, cluster)\n",
    "                        lesion_only[lesion_only < -500] = 0\n",
    "                        mean_HU = np.mean(lesion_only[np.nonzero(cluster)])\n",
    "                        median_HU = np.median(lesion_only[np.nonzero(cluster)])\n",
    "\n",
    "                        # add to data frame and move on\n",
    "                        df.loc[row_idx] = ['Hssayeni', str(file), labels[label_idx], hemorrhage_volume, mean_HU, median_HU, dx, dy, dz, num_slices, z_dist]\n",
    "                        row_idx += 1\n",
    "\n",
    "        print(df)\n",
    "\n",
    "    df.to_csv('../datasets/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1/Hssayeni_hemorrhage_characteristics.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot BHSD distributions (MANUSCRIPT FIGURE)\n",
    "Note: Mean +- standard deviation labels were manually added to the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_df = df # make copy of main df\n",
    "# Exclude SAH and IVH subtypes - out of scope for this work\n",
    "mask = fig_df['Type'] == 'SAH'\n",
    "fig_df = fig_df[~mask]\n",
    "mask = fig_df['Type'] == 'IVH'\n",
    "fig_df = fig_df[~mask]\n",
    "\n",
    "print('Mean values of each metric by hemorrhage type:')\n",
    "print(fig_df.groupby(['Type'])[['Mean_HU', 'Volume_[mL]']].mean())\n",
    "print(' ')\n",
    "print('Standard deviation of each metric by hemorrhage type:')\n",
    "print(fig_df.groupby(['Type'])[['Mean_HU', 'Volume_[mL]']].std())\n",
    "print(' ')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "sns.histplot(ax=axes[0], data=fig_df, x='Volume_[mL]', hue='Type', bins=30, kde=True)\n",
    "axes[0].set_title('(A) Volume by Hemorrhage Type')\n",
    "axes[0].set_xlabel('Volume [mL]')\n",
    "axes[0].set_xlim([-10, 100]) # there is a very small number of hemorrhages with volumes between 100-200 mL, excluding from visualization\n",
    "sns.histplot(ax=axes[1], data=fig_df, x='Mean_HU', hue='Type', bins=30, kde=True, legend=True)\n",
    "axes[1].set_title('(B) Mean HU by Hemorrhage Type')\n",
    "axes[1].set_xlabel('Mean HU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract volume KDE distributions for use in InSilicoIVH source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each KDE and extract x- and y- axis data\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25,4))\n",
    "fig.suptitle('Volume KDE for each hemorrhage type')\n",
    "axes[0].set_title('IPH')\n",
    "sns.kdeplot(ax=axes[0], data=df.loc[df['Type'] == 'IPH'], x=\"Volume_[mL]\", fill=True, alpha=0.5, thresh=0.02)\n",
    "x_IPH, y_IPH = sns.kdeplot(ax=axes[0], data=df.loc[df['Type'] == 'IPH'], x=\"Volume_[mL]\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[0].plot(x_IPH, y_IPH, '--r')\n",
    "\n",
    "axes[1].set_title('IVH')\n",
    "sns.kdeplot(ax=axes[1], data=df.loc[df['Type'] == 'IVH'], x=\"Volume_[mL]\", fill=True, alpha=0.5)\n",
    "x_IVH, y_IVH = sns.kdeplot(ax=axes[1], data=df.loc[df['Type'] == 'IVH'], x=\"Volume_[mL]\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[1].plot(x_IVH, y_IVH, '--r')\n",
    "\n",
    "axes[2].set_title('SDH')\n",
    "sns.kdeplot(ax=axes[2], data=df.loc[df['Type'] == 'SDH'], x=\"Volume_[mL]\", fill=True, alpha=0.5)\n",
    "x_SDH, y_SDH = sns.kdeplot(ax=axes[2], data=df.loc[df['Type'] == 'SDH'], x=\"Volume_[mL]\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[2].plot(x_SDH, y_SDH, '--r')\n",
    "\n",
    "axes[3].set_title('SAH')\n",
    "sns.kdeplot(ax=axes[3], data=df.loc[df['Type'] == 'SAH'], x=\"Volume_[mL]\", fill=True, alpha=0.5)\n",
    "x_SAH, y_SAH = sns.kdeplot(ax=axes[3], data=df.loc[df['Type'] == 'SAH'], x=\"Volume_[mL]\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[3].plot(x_SAH, y_SAH, '--r')\n",
    "\n",
    "axes[4].set_title('EDH')\n",
    "sns.kdeplot(ax=axes[4], data=df.loc[df['Type'] == 'EDH'], x=\"Volume_[mL]\", fill=True, alpha=0.5)\n",
    "x_EDH, y_EDH = sns.kdeplot(ax=axes[4], data=df.loc[df['Type'] == 'EDH'], x=\"Volume_[mL]\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[4].plot(x_EDH, y_EDH, '--r')\n",
    "\n",
    "_ = plt.setp(axes, xlim=(-50,225), ylim=(0,0.06))\n",
    "\n",
    "# Initialize dataframe\n",
    "df_volume = pd.DataFrame(columns=['IPH_volume', 'IPH_weight', \n",
    "                                  'IVH_volume', 'IVH_weight',\n",
    "                                  'SDH_volume', 'SDH_weight',\n",
    "                                  'SAH_volume', 'SAH_weight',\n",
    "                                  'EDH_volume', 'EDH_weight'])\n",
    "\n",
    "min_volume = 0.01\n",
    "max_volume = 100\n",
    "\n",
    "df_volume['IPH_volume'] = np.pad(x_IPH[np.where((x_IPH > min_volume) & (x_IPH < max_volume))], (0, 200-len(x_IPH[np.where((x_IPH > min_volume) & (x_IPH < max_volume))])), 'constant')\n",
    "df_volume['IPH_weight'] = np.pad(y_IPH[np.where((x_IPH > min_volume) & (x_IPH < max_volume))], (0, 200-len(x_IPH[np.where((x_IPH > min_volume) & (x_IPH < max_volume))])), 'constant')\n",
    "\n",
    "df_volume['IVH_volume'] = np.pad(x_IVH[np.where((x_IVH > min_volume) & (x_IVH < max_volume))], (0, 200-len(x_IVH[np.where((x_IVH > min_volume) & (x_IVH < max_volume))])), 'constant')\n",
    "df_volume['IVH_weight'] = np.pad(y_IVH[np.where((x_IVH > min_volume) & (x_IVH < max_volume))], (0, 200-len(x_IVH[np.where((x_IVH > min_volume) & (x_IVH < max_volume))])), 'constant')\n",
    "\n",
    "df_volume['SDH_volume'] = np.pad(x_SDH[np.where((x_SDH > min_volume) & (x_SDH < max_volume))], (0, 200-len(x_SDH[np.where((x_SDH > min_volume) & (x_SDH < max_volume))])), 'constant')\n",
    "df_volume['SDH_weight'] = np.pad(y_SDH[np.where((x_SDH > min_volume) & (x_SDH < max_volume))], (0, 200-len(x_SDH[np.where((x_SDH > min_volume) & (x_SDH < max_volume))])), 'constant')\n",
    "\n",
    "df_volume['SAH_volume'] = np.pad(x_SAH[np.where((x_SAH > min_volume) & (x_SAH < max_volume))], (0, 200-len(x_SAH[np.where((x_SAH > min_volume) & (x_SAH < max_volume))])), 'constant')\n",
    "df_volume['SAH_weight'] = np.pad(y_SAH[np.where((x_SAH > min_volume) & (x_SAH < max_volume))], (0, 200-len(x_SAH[np.where((x_SAH > min_volume) & (x_SAH < max_volume))])), 'constant')\n",
    "\n",
    "df_volume['EDH_volume'] = np.pad(x_EDH[np.where((x_EDH > min_volume) & (x_EDH < max_volume))], (0, 200-len(x_EDH[np.where((x_EDH > min_volume) & (x_EDH < max_volume))])), 'constant')\n",
    "df_volume['EDH_weight'] = np.pad(y_EDH[np.where((x_EDH > min_volume) & (x_EDH < max_volume))], (0, 200-len(x_EDH[np.where((x_EDH > min_volume) & (x_EDH < max_volume))])), 'constant')\n",
    "\n",
    "if save_distributions:\n",
    "    df_volume.to_csv('BHSD_volume_distributions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract HU KDE distributions for use in InSilicoIVH source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDES\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25,4))\n",
    "fig.suptitle('Mean HU KDE for each hemorrhage type')\n",
    "axes[0].set_title('IPH')\n",
    "sns.kdeplot(ax=axes[0], data=df.loc[df['Type'] == 'IPH'], x=\"Mean_HU\", fill=True, alpha=0.5, thresh=0.02)\n",
    "hu_IPH, den_IPH = sns.kdeplot(ax=axes[0], data=df.loc[df['Type'] == 'IPH'], x=\"Mean_HU\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[0].plot(hu_IPH, den_IPH, '--r')\n",
    "\n",
    "axes[1].set_title('IVH')\n",
    "sns.kdeplot(ax=axes[1], data=df.loc[df['Type'] == 'IVH'], x=\"Mean_HU\", fill=True, alpha=0.5)\n",
    "hu_IVH, den_IVH = sns.kdeplot(ax=axes[1], data=df.loc[df['Type'] == 'IVH'], x=\"Mean_HU\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[1].plot(hu_IVH, den_IVH, '--r')\n",
    "\n",
    "axes[2].set_title('SDH')\n",
    "sns.kdeplot(ax=axes[2], data=df.loc[df['Type'] == 'SDH'], x=\"Mean_HU\", fill=True, alpha=0.5)\n",
    "hu_SDH, den_SDH = sns.kdeplot(ax=axes[2], data=df.loc[df['Type'] == 'SDH'], x=\"Mean_HU\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[2].plot(hu_SDH, den_SDH, '--r')\n",
    "\n",
    "axes[3].set_title('SAH')\n",
    "sns.kdeplot(ax=axes[3], data=df.loc[df['Type'] == 'SAH'], x=\"Mean_HU\", fill=True, alpha=0.5)\n",
    "hu_SAH, den_SAH = sns.kdeplot(ax=axes[3], data=df.loc[df['Type'] == 'SAH'], x=\"Mean_HU\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[3].plot(hu_SAH, den_SAH, '--r')\n",
    "\n",
    "axes[4].set_title('EDH')\n",
    "sns.kdeplot(ax=axes[4], data=df.loc[df['Type'] == 'EDH'], x=\"Mean_HU\", fill=True, alpha=0.5)\n",
    "hu_EDH, den_EDH = sns.kdeplot(ax=axes[4], data=df.loc[df['Type'] == 'EDH'], x=\"Mean_HU\", alpha=0.5, thresh=0.02).lines[0].get_data()\n",
    "axes[4].plot(hu_EDH, den_EDH, '--r')\n",
    "\n",
    "_ = plt.setp(axes, xlim=(0, 100), ylim=(0,0.08))\n",
    "\n",
    "df_IPH_HU = pd.DataFrame(columns=['HU', 'weight'])\n",
    "df_IVH_HU = pd.DataFrame(columns=['HU', 'weight'])\n",
    "df_SDH_HU = pd.DataFrame(columns=['HU', 'weight'])\n",
    "df_SAH_HU = pd.DataFrame(columns=['HU', 'weight'])\n",
    "df_EDH_HU = pd.DataFrame(columns=['HU', 'weight'])\n",
    "\n",
    "df_HU = pd.DataFrame(columns=['IPH_HU', 'IPH_weight', \n",
    "                                  'IVH_HU', 'IVH_weight',\n",
    "                                  'SDH_HU', 'SDH_weight',\n",
    "                                  'SAH_HU', 'SAH_weight',\n",
    "                                  'EDH_HU', 'EDH_weight'])\n",
    "\n",
    "df_HU['IPH_HU'] = hu_IPH\n",
    "df_HU['IPH_weight'] = den_IPH\n",
    "\n",
    "df_HU['IVH_HU'] = hu_IVH\n",
    "df_HU['IVH_weight'] = den_IVH\n",
    "\n",
    "df_HU['SDH_HU'] = hu_SDH\n",
    "df_HU['SDH_weight'] = den_SDH\n",
    "\n",
    "df_HU['SAH_HU'] = hu_SAH\n",
    "df_HU['SAH_weight'] = den_SAH\n",
    "\n",
    "df_HU['EDH_HU'] = hu_EDH\n",
    "df_HU['EDH_weight'] = den_EDH\n",
    "\n",
    "if save_distributions:\n",
    "    df_HU.to_csv('BHSD_HU_distributions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insilicoich-pub1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
